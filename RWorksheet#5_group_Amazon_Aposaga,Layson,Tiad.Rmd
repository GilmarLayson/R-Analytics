---
title: "RWorksheet#5_group(Aposaga,Layson,Ti-ad)"
author: "James Cedrick Tiad"
date: "2024-11-18"
output: pdf_document
---

```{r}
url <- "https://www.amazon.com/s?i=specialty-aps&bbn=16225007011&rh=n%3A16225007011%2Cn%3A172456&ref=nav_em__nav_desktop_sa_intl_computer_accessories_and_peripherals_0_2_6_2"

session <- bow(url, user_agent = "Educational")
session

session_page <- scrape(session)

# Find all div elements with the specified class
div_elements <- html_nodes(session_page,'div.sg-col-4-of-24.sg-col-4-of-12.s-result-item.s-asin.sg-col-4-of-16.sg-col.s-widget-spacing-small.sg-col-4-of-20')

# Create empty vectors to store data
links <- character()
img_srcs <- character()
titles <- character()
prices <- character()
ratings <- character()

max_limit<- 30
for (i in 1:min(length(div_elements),max_limit)) {
  div_element <- div_elements[i]
  # Find the a element with class="a-link-normal s-no-outline" and get the link
  
  
  a_element <- html_node(div_element, 'a.a-link-normal.s-no-outline')
  link <- ifelse(!is.na(a_element), paste0("https://amazon.com", html_attr(a_element, "href")), '')
  
  
  # Find the img element with class="s-image" and get the link
  img_element <- html_node(div_element, 'img.s-image')
  img_src <- ifelse(!is.na(img_element), html_attr(img_element, "src"), '')
  
  # Find the span element with class="a-size-base-plus a-color-base a-text-normal" and get the title
  title_element <- html_node(div_element, 'span.a-size-base-plus.a-color-base.a-text-normal')
  title <- ifelse(!is.na(title_element), html_text(title_element), '')
  
  # Find the span element with class="a-price-whole" and get the price
  price_element <- html_node(div_element, 'span.a-price-whole')
  price <- ifelse(!is.na(price_element), html_text(price_element), '')
  
  # Find the span element with class="a-icon-alt" and get the ratings
  rating_element <- html_node(div_element, 'span.a-icon-alt')
  rating <- ifelse(!is.na(rating_element), html_text(rating_element), '')
  
  # Append data to vectors
  links <- c(links, link)
  img_srcs <- c(img_srcs, img_src)
  titles <- c(titles, title)
  prices <- c(prices, price)
  ratings <- c(ratings, rating)
}


# Create a data frame
product_df <- data.frame(Links = links, 
                         Images = img_srcs, 
                         Description = titles, 
                         Price = prices, 
                         Rating = ratings)

write.csv(product_df, "ComputerProd.csv")
```

```{r}
url <- "https://www.amazon.com/s?i=specialty-aps&bbn=4954955011&rh=n%3A4954955011%2Cn%3A%212617942011%2Cn%3A2747968011&ref=nav_em__nav_desktop_sa_intl_painting_drawing_supplies_0_2_8_2"

session <- bow(url,
               user_agent = "Student's Demo Educational")
session

session_page <- scrape(session)

# Find all div elements with the specified class
div_elements <- html_nodes(session_page,'div.sg-col-4-of-24.sg-col-4-of-12.s-result-item.s-asin.sg-col-4-of-16.sg-col.s-widget-spacing-small.sg-col-4-of-20')

# Create empty vectors to store data
links <- character()
img_srcs <- character()
titles <- character()
prices <- character()
ratings <- character()

max_limit<- 30
for (i in 1:min(length(div_elements),max_limit)) {
  div_element <- div_elements[i]
  # Find the a element with class="a-link-normal s-no-outline" and get the link
  
  
  a_element <- html_node(div_element, 'a.a-link-normal.s-no-outline')
  link <- ifelse(!is.na(a_element), paste0("https://amazon.com", html_attr(a_element, "href")), '')
  
  
  # Find the img element with class="s-image" and get the link
  img_element <- html_node(div_element, 'img.s-image')
  img_src <- ifelse(!is.na(img_element), html_attr(img_element, "src"), '')
  
  # Find the span element with class="a-size-base-plus a-color-base a-text-normal" and get the title
  title_element <- html_node(div_element, 'span.a-size-base-plus.a-color-base.a-text-normal')
  title <- ifelse(!is.na(title_element), html_text(title_element), '')
  
  # Find the span element with class="a-price-whole" and get the price
  price_element <- html_node(div_element, 'span.a-price-whole')
  price <- ifelse(!is.na(price_element), html_text(price_element), '')
  
  # Find the span element with class="a-icon-alt" and get the ratings
  rating_element <- html_node(div_element, 'span.a-icon-alt')
  rating <- ifelse(!is.na(rating_element), html_text(rating_element), '')
  
  # Append data to vectors
  links <- c(links, link)
  img_srcs <- c(img_srcs, img_src)
  titles <- c(titles, title)
  prices <- c(prices, price)
  ratings <- c(ratings, rating)
}


# Create a data frame
product_df <- data.frame(Links = links, 
                         Images = img_srcs, 
                         Description = titles, 
                         Price = prices, 
                         Rating = ratings)

write.csv(product_df, "ArtsCrafts.csv")
```

```{r}
url <- "https://www.amazon.com/s?i=specialty-aps&bbn=16225021011&rh=n%3A7141123011%2Cn%3A16225021011%2Cn%3A1040666&ref=nav_em__nav_desktop_sa_intl_clothing_0_2_15_2"

session <- bow(url,
               user_agent = "Student's Demo Educational")
session

session_page <- scrape(session)

# Find all div elements with the specified class
div_elements <- html_nodes(session_page,'div.sg-col-4-of-24.sg-col-4-of-12.s-result-item.s-asin.sg-col-4-of-16.sg-col.s-widget-spacing-small.sg-col-4-of-20')

# Create empty vectors to store data
links <- character()
img_srcs <- character()
titles <- character()
prices <- character()
ratings <- character()

max_limit<- 30
for (i in 1:min(length(div_elements),max_limit)) {
  div_element <- div_elements[i]
  # Find the a element with class="a-link-normal s-no-outline" and get the link
  
  
  a_element <- html_node(div_element, 'a.a-link-normal.s-no-outline')
  link <- ifelse(!is.na(a_element), paste0("https://amazon.com", html_attr(a_element, "href")), '')
  
  
  # Find the img element with class="s-image" and get the link
  img_element <- html_node(div_element, 'img.s-image')
  img_src <- ifelse(!is.na(img_element), html_attr(img_element, "src"), '')
  
  # Find the span element with class="a-size-base-plus a-color-base a-text-normal" and get the title
  title_element <- html_node(div_element, 'span.a-size-base-plus.a-color-base.a-text-normal')
  title <- ifelse(!is.na(title_element), html_text(title_element), '')
  
  # Find the span element with class="a-price-whole" and get the price
  price_element <- html_node(div_element, 'span.a-price-whole')
  price <- ifelse(!is.na(price_element), html_text(price_element), '')
  
  # Find the span element with class="a-icon-alt" and get the ratings
  rating_element <- html_node(div_element, 'span.a-icon-alt')
  rating <- ifelse(!is.na(rating_element), html_text(rating_element), '')
  
  # Append data to vectors
  links <- c(links, link)
  img_srcs <- c(img_srcs, img_src)
  titles <- c(titles, title)
  prices <- c(prices, price)
  ratings <- c(ratings, rating)
}

  
# Create a data frame
product_df <- data.frame(Links = links, 
                         Images = img_srcs, 
                         Title = titles, 
                         Price = prices, 
                         Rating = ratings)

write.csv(product_df, "BoysClothing.csv")
```

```{r}
url <- "https://www.amazon.com/s?i=specialty-aps&bbn=16225020011&rh=n%3A7141123011%2Cn%3A16225020011%2Cn%3A1040664&ref=nav_em__nav_desktop_sa_intl_clothing_0_2_14_2"

session <- bow(url,
               user_agent = "Student's Demo Educational")
session

session_page <- scrape(session)

# Find all div elements with the specified class
div_elements <- html_nodes(session_page,'div.sg-col-4-of-24.sg-col-4-of-12.s-result-item.s-asin.sg-col-4-of-16.sg-col.s-widget-spacing-small.sg-col-4-of-20')

# Create empty vectors to store data
links <- character()
img_srcs <- character()
titles <- character()
prices <- character()
ratings <- character()

max_limit<- 30
for (i in 1:min(length(div_elements),max_limit)) {
  div_element <- div_elements[i]
  # Find the a element with class="a-link-normal s-no-outline" and get the link
  
  
  a_element <- html_node(div_element, 'a.a-link-normal.s-no-outline')
  link <- ifelse(!is.na(a_element), paste0("https://amazon.com", html_attr(a_element, "href")), '')
  
  
  # Find the img element with class="s-image" and get the link
  img_element <- html_node(div_element, 'img.s-image')
  img_src <- ifelse(!is.na(img_element), html_attr(img_element, "src"), '')
  
  # Find the span element with class="a-size-base-plus a-color-base a-text-normal" and get the title
  title_element <- html_node(div_element, 'span.a-size-base-plus.a-color-base.a-text-normal')
  title <- ifelse(!is.na(title_element), html_text(title_element), '')
  
  # Find the span element with class="a-price-whole" and get the price
  price_element <- html_node(div_element, 'span.a-price-whole')
  price <- ifelse(!is.na(price_element), html_text(price_element), '')
  
  # Find the span element with class="a-icon-alt" and get the ratings
  rating_element <- html_node(div_element, 'span.a-icon-alt')
  rating <- ifelse(!is.na(rating_element), html_text(rating_element), '')
  
  # Append data to vectors
  links <- c(links, link)
  img_srcs <- c(img_srcs, img_src)
  titles <- c(titles, title)
  prices <- c(prices, price)
  ratings <- c(ratings, rating)
}

  
# Create a data frame
product_df <- data.frame(Links = links, 
                         Images = img_srcs, 
                         Title = titles, 
                         Price = prices, 
                         Rating = ratings)

write.csv(product_df, "GirlsClothing.csv")
```

```{r}
url <- "https://www.amazon.com/s?i=specialty-aps&bbn=16225013011&rh=n%3A%2116225013011%2Cn%3A2975312011&ref=nav_em__nav_desktop_sa_intl_dogs_0_2_21_2"

session <- bow(url,
               user_agent = "Student's Demo Educational")
session

session_page <- scrape(session)

# Find all div elements with the specified class
div_elements <- html_nodes(session_page,'div.sg-col-4-of-24.sg-col-4-of-12.s-result-item.s-asin.sg-col-4-of-16.sg-col.s-widget-spacing-small.sg-col-4-of-20')

# Create empty vectors to store data
links <- character()
img_srcs <- character()
titles <- character()
prices <- character()
ratings <- character()

max_limit<- 30
for (i in 1:min(length(div_elements),max_limit)) {
  div_element <- div_elements[i] 
  # Find the a element with class="a-link-normal s-no-outline" and get the link
  
  
  a_element <- html_node(div_element, 'a.a-link-normal.s-no-outline')
  link <- ifelse(!is.na(a_element), paste0("https://amazon.com", html_attr(a_element, "href")), '')
  
  
  # Find the img element with class="s-image" and get the link
  img_element <- html_node(div_element, 'img.s-image')
  img_src <- ifelse(!is.na(img_element), html_attr(img_element, "src"), '')
  
  # Find the span element with class="a-size-base-plus a-color-base a-text-normal" and get the title
  title_element <- html_node(div_element, 'span.a-size-base-plus.a-color-base.a-text-normal')
  title <- ifelse(!is.na(title_element), html_text(title_element), '')
  
  # Find the span element with class="a-price-whole" and get the price
  price_element <- html_node(div_element, 'span.a-price-whole')
  price <- ifelse(!is.na(price_element), html_text(price_element), '')
  
  # Find the span element with class="a-icon-alt" and get the ratings
  rating_element <- html_node(div_element, 'span.a-icon-alt')
  rating <- ifelse(!is.na(rating_element), html_text(rating_element), '')
  
  # Append data to vectors
  links <- c(links, link)
  img_srcs <- c(img_srcs, img_src)
  titles <- c(titles, title)
  prices <- c(prices, price)
  ratings <- c(ratings, rating)
}

  
# Create a data frame
product_df <- data.frame(Links = links, 
                         Images = img_srcs, 
                         Title = titles, 
                         Price = prices, 
                         Rating = ratings)

write.csv(product_df, "DogSupplies.csv")
```

